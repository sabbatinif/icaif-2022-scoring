\documentclass[sigconf]{acmart}

\usepackage{icaif-2022-scoring}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[ICAIF '22]{Workshop on Explainable AI in Finance}{November 2, 2022}{New York, NY}
%\acmPrice{15.00}
%\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{The Need of Evaluation Metrics for Symbolic Knowledge Extracted from Machine Learning Black Boxes}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Federico Sabbatini}
\authornote{Corresponding author.}
\email{f.sabbatini1@campus.uniurb.it}
\orcid{0000-0002-0532-6777}
\affiliation{%
	\institution{University of Urbino}
	%\streetaddress{Via S. Chiara, 27}
	\city{Urbino}
	\country{Italy}
	%\postcode{61029}
}

\author{Roberta Calegari}
\email{roberta.calegari@unibo.it}
\orcid{0000-0003-3794-2942}
\affiliation{%
  \institution{\textsc{Alma Mater Studiorum}---University of Bologna}
  %\streetaddress{}
  \city{Bologna}
  \country{Italy}
  %\postcode{}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{F. Sabbatini, R. Calegari}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  As opaque decision systems are being increasingly exploited in practically any application field, issues about their lack of human readability are a concrete source of concern for end-users wanting to apply them in critical domains.
  %
  Amongst the proposals available in the literature to associate human-interpretable knowledge with the accurate predictions provided by opaque models there are rule extraction techniques, able to obtain symbolic knowledge suitable for human comprehension.
  %
  However, the problem of objectively assessing in a quantitative way the readability degree of the extracted knowledge is still open.
  %
  A solution to this problem would be of pivotal importance, for instance, to enable the automatic comparison between a set of different knowledge representations, paving the way for the development of parameter autotuning algorithms for knowledge extractors.
  %
  In this paper we discuss in details the criticalities about readability assessment, taking into account the most common knowledge representations and highlighting the most puzzling issues.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%%
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10010147.10010178.10010187</concept_id>
	<concept_desc>Computing methodologies~Knowledge representation and reasoning</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10010147.10010257</concept_id>
	<concept_desc>Computing methodologies~Machine learning</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Knowledge representation and reasoning}
\ccsdesc[500]{Computing methodologies~Machine learning}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{explainable artificial intelligence, symbolic knowledge extraction, readability metrics}

\maketitle

\section{Introduction and Background}

The ubiquitous presence of sub-symbolic machine learning predictors in the large majority of decision systems~\cite{rocha2012far} offers advantages as well as drawbacks.
%
Amongst the former, the enormous predictive capabilities of sub-symbolic predictors have to be mentioned.
%
Predictive performance of models is usually proportional to their internal complexity, intended as amount of parameters to be trained and/or knowledge representation structure.
%
For instance, knowledge in deep neural network is represented as neuron weights and biases, that are too many to enable human inspection.
%
From here the most severe disadvantage of sub-symbolic models, i.e., the lack of human interpretability.
%
For this reason models of this kind are called \email{black boxes} (BB).

When dealing with critical applications -- i.e., in medical or financial areas -- such a lack of human awareness is not acceptable and makes BB models impracticable.
%
Different strategies are present in the literature to overcome this issue~\cite{guidotti2018survey}:
%
\begin{inlinelist}
	\item rely on human-interpretable models, as shallow decision trees~\cite{Rudin2019}; or
	\item apply symbolic knowledge extraction (SKE) techniques to the BB~\cite{KENNY2021103459}.
\end{inlinelist}

The amount of SKE algorithms available in the literature is constantly increasing, thanks to the software support provided by object-oriented frameworks for machine learning (e.g., Scikit-learn\footnote{\vurl{https://scikit-learn.org/stable}}~\cite{PedregosaVGMTGBPWDVPCBPD11} for Python or Smile\footnote{\vurl{https://haifengl.github.io}} for the Java Virtual Machine) as well as to the developing of dedicated frameworks (e.g., \psyke{}~\cite{psyke-woa2021,psyke-ia2022,psyke-extraamas2022}).

SKE procedures belongs to two different paradigms~\cite{andrews1995survey}, i.e., they can be \emph{decompositional} if they inspect the internal structure of the BB or \emph{pedagogical} if they only observe the BB response to given input.
%
Since in decompositional methods type and structure of the BB play a fundamental role, they are usually not general-purpose and designed for specific models, for instance only neural networks with a fixed amount of hidden layers, as in the case of \textsc{ReFANN}~\cite{setiono2002extraction}.
%
Conversely, pedagogical approaches result to be suitable for any BB predictor.
%
When SKE techniques mix elements of the two categories it is possible to define the approaches as \emph{eclectic}, however they may be considered enclosed in the decompositional set, since they require some sort of internal inspection.

Amongst the application areas of SKE there are financial~\cite{baesens2001building,baesens2003using,steiner2006using} and medical fields~\cite{bologna1997three,franco2007early,hayashi2000comparison}, but not only~\cite{setiono2011rule,sabbatini22LPFSKE,azcarraga2012keyword,hofmann2003rule}.
%
Examples of extractors generally achieving good results are \cart{}~\cite{breiman1984classification}, \trepan{}~\cite{craven1996extracting}, \gridex{}~\cite{gridex-extraamas2021} and \gridrex{}~\cite{gridrex-kr2022}.
%
Of course a number of alternatives are present in the literature~\cite{craven1994using,huysmans2006iter,barakat2005eclectic,martens2007comprehensible}, depending on the task at hand.
%
A common trait of every extractor is given by their output, that is some sort of human-interpretable knowledge.
%
The knowledge usually follows a list or tree representation, where each item (leaf) of the list (tree) corresponds to a specific rule having predictive power.
%
The human-readability extent of a knowledge is bounded to the number of rules it contains and, recursively, to the readability extent of each rule, in turn.
%
Indeed, rules may follow several formats with different degrees of conciseness even when having the same semantics.
%
For this reason it is a quite challenging task the quantitative assessment of knowledge readability through an unbiased score.
%
The lacking of such a score prevents the design and implementation of procedures to automatically tune extractor parameters, since a robust method to compare the extractors' outputs is currently missing.
%
Accordingly, in the following Section we provide a more detailed discussion about the readability assessment, highlighting the most challenging difficulties clustered on the basis of the knowledge representation chosen by extraction algorithms.

\section{Evaluating Extracted Knowledge}

The knowledge extracted via SKE techniques can be evaluated through different interesting indicators, for instance:
%
\begin{inlinelist}
	\item the predictive performance of the knowledge rules w.r.t.\ the data or the BB predictions (this latter is called \emph{fidelity});
	\item the readability extent from a human perspective; and
	\item the input space coverage.
\end{inlinelist}

It is easy to assess the knowledge predictive performance with the same scoring function adopted to evaluate the underlying BB.
%
Adequate scoring metrics are, for instance, the accuracy and F$_1$ scores for classification tasks and the mean absolute/squared error and R$^2$ score for regression tasks.
%
Of course this indicator is relevant, since it represents the ultimate way to assess if the knowledge is suitable to draw predictions.

The input space coverage can be also measured in a trivial way, e.g., by observing how many data set instances are covered by the extracted rules, or by performing some kind of equal-spaced or random sampling inside the input space and checking how many data points are covered.
%
Obviously, the latter solution is more demanding for high-dimensional data sets and may have little significance in case the data set is sparse and thus characterised by empty regions.
%
This indicator is important because a knowledge that is extremely human readable (e.g., composed of a single, simple rule) and having great predictive performance (e.g., 100\% accuracy) is actually useless if it covers an infinitesimally small region of the input feature space.

A different and more articulated reasoning is required about human-readability assessment.
%
Is is possible to distinguish between 2 different levels of readability, both related to the presentation of the extracted knowledge to users.
%
We could consider a \emph{macrolevel} about the knowledge shape and dimension -- for instance if it is represented as a tree, a list, a table, etc. -- and how many leaves, rules, rows/columns, etc., are present, respectively.
%
We then may consider a \emph{microlevel} to recursively take into account the same indicators (shape and complexity intended as number of elements) for each element composing the knowledge.
%
Examples may be the kind of preconditions of each element (e.g., oblique rules, \mofn{} tree nodes) and how many variables, constants and predicates appear inside them.
%
This is far from being a trivial task, since equivalent concepts may be represented according to different notations, each one having its own conciseness and expressiveness.
%
In the following both macrolevel and microlevel are examined in details, showing that the most challenging issues are related to the latter.

\subsection{Macrolevel}\label{ssec:macro}

The most common knowledge representations, when it has to be presented to human users, are decision lists~\cite{freitas2014comprehensible,huysmans2011empirical}, trees~\cite{quinlan1993c4,breiman1984classification} and tables~\cite{sethi2012kdruleex}.
%
The reason behind their massive exploitation is related to their high understandability for humans.

\paragraph{Decision lists}

Knowledge having this shape is represented as a list of rules, where each rule has a precondition and a postcondition.
%
Preconditions usually are conjunctions (or less frequently disjunctions) of constraints on the input variables.
%
Postconditions, on the other hand, are the associated outputs.
%
Thus, a rule provides output predictions for all and only those input instances satisfying the rule precondition.
%
The complexity of the list may be easily assessed through the amount of contained rules.

Lists may be exhaustive, if it is always possible to draw predictions for input instances (i.e., at least one rule can be applied to each input instance), or not.
%
This characteristic does not affect the knowledge readability, but only the input space coverage.

Furthermore, rules may be overlapping, if more than one rule may be applied at the same time to a single input instance, or not (if at most one rule can be applied).
%
This feature may affect the overall readability, but actually it can be neglected since knowledge extracted via SKE techniques usually relies on non-overlapping rules, or the overlapping rules have some degree of confidence thanks to which it is possible to select a single rule for each input sample.

Rule lists may be hierarchical, if some rules have as postcondition a sublist of rules.
%
They can be trivially converted into a non-hierarchical list, so there is no need to consider this specific scenario.

Finally, rule lists may be ordered -- when rule number $n$ is evaluated only if preconditions of rules $1 \dots n-1$ are not satisfied -- or unordered---if, otherwise, any rule can be chosen without taking into account the preceding in the list.
%
Human readability is strongly impacted by the list ordering, since human users must be conscious that a rule can be selected only if all the preceding have been already tested.
%
In other words, rules number $n$ implicitly carries along information about the preconditions of other distinct $n-1$ rules, i.e., implicit information that is inherently coded within the ordering.
%
To give an example, the fourth rule in an unordered set may be something like ``output is $post_4$ if $pre_4$'', and humans are able to read and apply the rule as is.
%
We remark that $pre_i$ and $post_i$ are the precondition and postcondition, respectively, associated to the $i$-th rule of the list.
%
The same rule in an ordered set should be considered by humans as ``output is $post_4$ if $pre_4, not(pre_3), not(pre_2), not(pre_1)$'', where $not(pre)$ is true if $pre$ is not satisfied and the comma operator represents logical conjunction.
%
Of course the readability of ordered sets is hindered by this consideration, especially for a large amount of rules.

\paragraph{Decision trees}

Knowledge adhering to this representation differs from rule lists since in this case rules are represented as complete paths from the tree root to the leaves.
%
Each distinct path from root to a different leaf is a rule, so the complexity of the knowledge is equal to the number of leaves (that in turn is equal to the number of rules).
%
Decision trees are usually binary trees storing a constraint on one or more input variables in each internal node and a decision in each leaf.
%
As a consequence, the precondition of a rule is given by the logical conjunction of the constraints corresponding to the internal nodes.
%
Conversely, the postcondition is associated with the leaf.

Decision trees are always exhaustive by design, since it is always possible to draw predictions for the given instances.
%
The provided rules are also non-overlapping, because only one leaf may be reached when examining an input sample.

We believe that the best option to analyse decision tree human readability is to convert the tree into a (possibly ordered) rule list, and then stick to the same scoring metrics adopted for lists.

\paragraph{Decision tables}

Knowledge following this representation is provided in tabular form.
%
Usually each column (or row) represents a variable and each row (or column) is associated to a rule.
%
In the following we associate columns with variables and rows with rules.
%
The cell obtained by intersecting column $j$ with row $k$ represents the constraint on input variable $j$ in the $k$-th rule.
%
If variable $j$ is the output variable, then the cell contains the output decision of the rule.
%
Usually the output column is the last.

By assuming this notation, it is straightforward to obtain rules having as precondition the conjunction of all the constraints on a same row and as postcondition the contents of the last row cell.
%
It is as well trivial to obtain the complexity of the table in terms of number of rows (equal to the rule amount).

In order to enable a fair comparison between decision tables and other kind of knowledge shape, the former may be easily converted into (generally unordered) rule lists.

\paragraph{Macrolevel observations}

\Cref{ssec:macro} may be resumed in few considerations: decision lists, trees and tables are easily comparable in terms of human readability, since even if they provide knowledge according to different formats, it is always possible to obtain an equivalent unordered list without predictive losses.
%
The equivalent list will have different individual rules -- e.g., more complex than those in the original knowledge -- but the knowledge macrolevel complexity will not be affected---e.g., the rule amount has to remain the same.
%
In this way it is possible to perform a fair comparison amongst different knowledge shapes by only focusing on the macrolevel complexity and on further considerations about the microlevel.
%
During a macrolevel readability assessment, a knowledge having smaller complexity (i.e., fewer rules) should be preferred over other solutions.

\subsection{Microlevel}

When extracting knowledge, SKE techniques output rules adhering to different representations.
%
Amongst the most widespread kinds we can find propositional, \mofn{}~\cite{TowellS91,murphy1991id2}, fuzzy~\cite{HorikawaFU92,Berenji91} and oblique~\cite{Setiono00,SetionoL97} rules.
%
In any case, rules are expressed as a conjunction, or disjunction, of literals having different formats.

\paragraph{Propositional rules}

The most adopted rule format is the propositional one, where literals are simple predicates expressing equalities (in positive or negative form) or inequalities between the value of an input feature and one or more constants.
%
The basic notations for equalities and inequalities are $X = u$, $Y \neq v$; $Z \lessgtr w$, where $X,Y,Z$ are input features and $u,v,w$ are constant values.
%
Basic literals may be extended to interval and set inclusion/exclusion, to group together a disjunction of a set of literals.

This first step to achieve better conciseness comes along with a major readability issue.
%
Indeed, a knowledge may contain two rules having the same output and only one precondition each, composed of a basic literal involving the same variable but compared to different constants, for instance ``output is $A$ if $color=blue$'' and ``output is $A$ if $color=red$''.
%
Rules of this kind may be collapsed into a single rule: ``output is $A$ if $color=blue$ or $color=red$''.
%
But this is not the only solution, since the rule ``output is $A$ if $color \in \{blue,red\}$'' is also equivalent.

Starting from a trivial example it is easy to notice that even one categorical feature assuming at least 2 distinct values leads to 3 different knowledge representations, all equivalent.
%
The readability of an output knowledge should be proportional to the effort required by a human user to understand and apply its rules.
%
In this case, the first knowledge has 2 rules, 2 variable occurrences and as many predicated and constants.
%
The second has 1 rule and the same values for other indicators.
%
The third knowledge has 1 rule, 1 variable occurrence, 1 predicate and 2 constant values.
%
Obviously, it is preferable to have 1 rule, and this is decided via macrolevel considerations.
%
Amongst the second and third knowledge rules there is not a substantial readability difference, since both of them imply the human user to evaluate the $X$ variable and compare it with two constant values.
%
As a result, we obtain that a raw counting of variable occurrences, predicates and constants is not suitable to express microlevel readability, even though they are perfect indicators for rule conciseness (in this case the fewer, the better).
%
Furthermore, one may observe that the more a rule adopts concise literals, the more it is difficult to understand the rule and to associate a readability score to it, as shown in the following.

\paragraph{\mofn{} rules}

Literals may be expressed as groups, where the group is satisfied if at least one amongst the possible constraints is satisfied, as shown in the previous paragraph.
%
This definition may be further relaxed, and a group of $N$ literals can be considered as satisfied if at least $M$ constraints are satisfied.
%
\mofn{} rules are exactly defined in this manner.
%
They enable a much higher degree of conciseness, however our opinion is that human users encounter more difficulties in understanding the rule.
%
As an example, one may think about a 4-of-9 rule.

Large $N$ values also obfuscate the real impact of individual variables on the final prediction.
%
Furthermore, it is quite challenging the mapping of \mofn{} rules to readability scores, since their readability decreases w.r.t.\ both $M$ and $N$.
%
For instance, 1-of-5 rules are more easily understandable than 3-of-5 or 1-of-10 rules.
%
But analogous claims about 5-of-9 vs. 4-of-10 rules cannot be easily stated.

\paragraph{Fuzzy rules}

If sets and intervals in preconditions are substituted with string labels and these labels correspond to the belonging to a defined set/interval within a certain confidence degree, rules are called fuzzy.
%
For instance, ``$X \in [0.3, 0.6]$'' could be equivalent to ``$X$ is $medium$'', by assuming the $X$ variable ranging in the [0, 1] interval.
%
The conciseness of this notation allows literals to have more flexible intervals (e.g., also [0.45, 0.65] could be considered as $medium$, with a different degree of confidence).
%
Outputs associated with fuzzy rules also have a confidence degree, depending on the one of corresponding preconditions.
%
As a consequence, human users reading a fuzzy rule need to
%
\begin{inlinelist}
	\item be aware of the underlying fuzzy labelling semantics;
	\item assign a degree of confidence to each literal in the rule precondition;
	\item read the postcondition and calculate the corresponding confidence.
\end{inlinelist}
%
We believe that it would be far more readable a direct, simple basic notation.
%
Since it is not possible to numerically assess the introduced human-interpretability hindrance, it is also hard to assign a readability score to fuzzy rules.

\paragraph{Oblique rules}

When dealing with numerical attributes, rule literals may be expressed as inequalities involving a linear combination of the input variables and a constant threshold.
%
On the input feature space these rules represent oblique hyperplanes.

Knowledge conciseness benefits from the application of oblique rules, since the exploitation of composite features is enabled, however in our opinion the human readability pays a high price.
%
One may think about the description of a concrete object to be classified.
%
Such an object may be represented through weight, volume and position.
%
Classification involving input feature separately is easy for humans.
%
The same is not true if human users have to consider, for instance, a linear combination of weight and position.
%
For this reason, the same final considerations about the fuzzy rule readability hindrance also hold for oblique rules.

\paragraph{Microlevel observations}

Even if the macrolevel knowledge complexity is quite easy to be assessed, the same does not hold at microlevel, because of the variety of adopted rule notations.
%
Different SKE algorithms adopt different notations and each one comes along its proper conciseness and human-interpretability degree.
%
Unfortunately, it is not possible to convert the various formats into a canonical, comparable notation and for this reason the problem of assigning a readability score to individual rules is a major open issue in the assessment of the extracted knowledge quality.

\section{Conclusions}

In this paper we analysed the most common formats and notations used to represent the knowledge extracted via SKE techniques from black-box models in order to highlight suitable metrics to evaluate the knowledge quality.
%
We showed that quality should encompass predictive performance, input space coverage and knowledge readability.
%
As for the latter, readability can be observed at a macrolevel -- as shape and complexity of the knowledge itself -- and at a microlevel---as shape and complexity of knowledge rules.
%
We showed that at a macrolevel the knowledge may be easily compared.
%
Conversely, we pointed out the most tricky characteristics of microlevel considerations, to favour further studies and discussion on the topic.
%
Our goal is to find a suitable metric to assess the knowledge quality in a fair, quantitative and objective manner, without neglecting its readability and our future works will be focused on this area.

%\begin{figure}[h]
%  \centering
%  \includegraphics[width=\linewidth]{sample-franklin}
%  \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%    Ewing, Inc. [Public domain], via Wikimedia
%    Commons. (\url{https://goo.gl/VLCRBB}).}
%  \Description{A woman and a girl in white dresses sit in an open car.}
%\end{figure}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
%\begin{acks}
%...
%\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{icaif-2022-scoring}

\end{document}
\endinput